{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to pheval.llm, formerly MALCO","text":"<p>To systematically assess and evaluate an LLM's ability to perform differential diagnostics tasks, we employed prompts programatically created with phenopacket2prompt, thereby avoiding any patient privacy issues. The original data are phenopackets located at phenopacket-store. A programmatic approach for scoring and grounding results is also developed, made possible thanks to the ontological structure of the Mondo Disease Ontology.</p> <p>Two main analyses are carried out: - A benchmark of some openAI GPT-models against a state of the art tool for differential diagnostics, Exomiser. The bottom line, Exomiser clearly outperforms the LLMs. - A comparison of gpt-4o's ability to carry out differential diagnosis when prompted in different languages. </p>"},{"location":"#project-layout","title":"Project layout","text":"<p>The description of the steps we take are found in the figure below .</p>"},{"location":"analysis/","title":"Scoring","text":"<p>In order to fairly score clinically accurate diagnoses - considering we are only using phenotypic data - we needed to match the grounded answers by an LLM (or by Exomiser) to the correct result present in the phenopacket, consisting of an OMIM identifier. This is illustrated in the image below.  .</p>"},{"location":"analysis/#statistics","title":"Statistics","text":""},{"location":"analysis/#more-tbd","title":"More TBD","text":""},{"location":"layout/","title":"Layout","text":"<p>The first part of the code does:</p>"},{"location":"layout/#prepare-step","title":"Prepare step","text":""},{"location":"layout/#run-step","title":"Run step","text":""},{"location":"layout/#post-process-step","title":"Post process step","text":""},{"location":"reference/","title":"Reference","text":"<p>The grounding happens via</p>"},{"location":"reference/#src.malco.process.mondo_score_utils.omim_mappings","title":"<code>omim_mappings(term, adapter)</code>","text":"<p>Get the OMIM mappings for a term.</p> <p>Example:</p> <p>from oaklib import get_adapter omim_mappings(\"MONDO:0007566\", get_adapter(\"sqlite:obo:mondo\")) ['OMIM:132800']</p> <p>Parameters:</p> Name Type Description Default <code>term</code> <code>str</code> <p>The term.</p> required <code>adapter</code> <code>OboGraphInterface</code> <p>The mondo adapter.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>List[str]</code> <p>The OMIM mappings.</p> Source code in <code>src/malco/process/mondo_score_utils.py</code> <pre><code>def omim_mappings(term: str, adapter: OboGraphInterface) -&gt; List[str]:\n    \"\"\"\n    Get the OMIM mappings for a term.\n\n    Example:\n\n    &gt;&gt;&gt; from oaklib import get_adapter\n    &gt;&gt;&gt; omim_mappings(\"MONDO:0007566\", get_adapter(\"sqlite:obo:mondo\"))\n    ['OMIM:132800']\n\n    Args:\n        term (str): The term.\n        adapter: The mondo adapter.\n\n    Returns:\n        str: The OMIM mappings.\n    \"\"\"\n    omims = []\n    for m in adapter.sssom_mappings([term], source=\"OMIM\"):\n        if m.predicate_id == \"skos:exactMatch\":\n            omims.append(m.object_id)\n    return omims\n</code></pre>"},{"location":"reference/#src.malco.process.mondo_score_utils.score_grounded_result","title":"<code>score_grounded_result(prediction, ground_truth, mondo, cache=None)</code>","text":"<p>Score the grounded result.</p> <p>Exact match:</p> <p>from oaklib import get_adapter score_grounded_result(\"OMIM:132800\", \"OMIM:132800\", get_adapter(\"sqlite:obo:mondo\")) 1.0</p> <p>The predicted Mondo is equivalent to the ground truth OMIM (via skos:exactMatches in Mondo):</p> <p>score_grounded_result(\"MONDO:0007566\", \"OMIM:132800\", get_adapter(\"sqlite:obo:mondo\")) 1.0</p> <p>The predicted Mondo is a disease entity that groups multiple OMIMs, one of which is the ground truth:</p> <p>score_grounded_result(\"MONDO:0008029\", \"OMIM:158810\", get_adapter(\"sqlite:obo:mondo\")) 0.5</p> <p>Parameters:</p> Name Type Description Default <code>prediction</code> <code>str</code> <p>The prediction.</p> required <code>ground_truth</code> <code>str</code> <p>The ground truth.</p> required <code>mondo</code> <code>OboGraphInterface</code> <p>The mondo adapter.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The score.</p> Source code in <code>src/malco/process/mondo_score_utils.py</code> <pre><code>def score_grounded_result(\n    prediction: str, ground_truth: str, mondo: OboGraphInterface, cache=None\n) -&gt; float:\n    \"\"\"\n    Score the grounded result.\n\n    Exact match:\n    &gt;&gt;&gt; from oaklib import get_adapter\n    &gt;&gt;&gt; score_grounded_result(\"OMIM:132800\", \"OMIM:132800\", get_adapter(\"sqlite:obo:mondo\"))\n    1.0\n\n    The predicted Mondo is equivalent to the ground truth OMIM\n    (via skos:exactMatches in Mondo):\n\n    &gt;&gt;&gt; score_grounded_result(\"MONDO:0007566\", \"OMIM:132800\", get_adapter(\"sqlite:obo:mondo\"))\n    1.0\n\n    The predicted Mondo is a disease entity that groups multiple\n    OMIMs, one of which is the ground truth:\n\n    &gt;&gt;&gt; score_grounded_result(\"MONDO:0008029\", \"OMIM:158810\", get_adapter(\"sqlite:obo:mondo\"))\n    0.5\n\n    Args:\n        prediction (str): The prediction.\n        ground_truth (str): The ground truth.\n        mondo: The mondo adapter.\n\n    Returns:\n        float: The score.\n    \"\"\"\n    if not isinstance(mondo, MappingProviderInterface):\n        raise ValueError(\"Adapter is not an MappingProviderInterface\")\n\n    if prediction == ground_truth:\n        # predication is the correct OMIM\n        return FULL_SCORE\n\n    ground_truths = get_ground_truth_from_cache_or_compute(prediction, mondo, cache)\n    if ground_truth in ground_truths:\n        # prediction is a MONDO that directly maps to a correct OMIM\n        return FULL_SCORE\n\n    descendants_list = mondo.descendants([prediction], predicates=[IS_A], reflexive=True)\n    for mondo_descendant in descendants_list:\n        ground_truths = get_ground_truth_from_cache_or_compute(mondo_descendant, mondo, cache)\n        if ground_truth in ground_truths:\n            # prediction is a MONDO that maps to a correct OMIM via a descendant\n            return PARTIAL_SCORE\n    return 0.0\n</code></pre>"},{"location":"run/","title":"Grounding","text":"<p>Since LLMs today, up to November 2024, show little ability to precisely and reliably return unique identifiers of some entity present in a database, we need to deal with this issue. In order to transform some human language disease name such as \"cystic fibrosis\" into its corresponding OMIM identifier OMIM:219700 we use the following approach:</p> <ol> <li>First, we try exact lexical matching between the LLMs reply and the OMIM diseases label.</li> <li>Then we run CurateGPT on the remaining ones that have not been grounded.</li> </ol> <p>We remark here that we ground to MONDO.</p>"},{"location":"run/#ontogpt","title":"OntoGPT","text":""},{"location":"setup/","title":"Setup","text":"<p>Before starting a run take care of editing the yaml as follows:</p> <ul> <li>The first line contains a non-empty comma-separated list of (supported) language codes between double quotation marks in which one wishes to prompt.</li> <li>The second line contains a non-empty comma-separated list of (supported) model names between double quotation marks which one wishes to prompt.</li> <li>The third line contains two comma-separated binary entries, represented by 0 (false) and 1 (true). The first set to true runs the prompting and grounding, i.e. the run step, the second one executes the scoring and the rest of the analysis, i.e. the post processing step. </li> </ul> <p>At this point one can install and run the code by doing: <pre><code>poetry install\npoetry env activate\n#TODO\n</code></pre></p> <p>As an example, the input file file will execute only the post_process block for English, prompting the models gpt-4, gpt-3.5-turbo, gpt-4o, and gpt-4-turbo.</p>"}]}